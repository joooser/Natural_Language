{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Modelos_clasificacion.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "rT7mmVnvFAcm"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joooser/Natural_Language/blob/main/Modelos_clasificacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6YTaQq9dCh0E"
      },
      "source": [
        "# Clasificación de palabras (por género de nombre)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5co_TuOhC4ze",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "outputId": "6ed198ee-9cb9-48b9-ab74-db9655585c0e"
      },
      "source": [
        "import nltk, random\n",
        "nltk.download('names')\n",
        "from nltk.corpus import names "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package names to /root/nltk_data...\n",
            "[nltk_data]   Package names is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijhsE2PBFYxm"
      },
      "source": [
        "**Función básica de extracción de atributos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0kKV62lCZ55"
      },
      "source": [
        "# definición de atributos relevantes\n",
        "def atributos(palabra):\n",
        "\treturn {'ultima_letra': palabra[-1]}\n",
        "\n",
        "tagset = ([(name, 'male') for name in names.words('male.txt')] + [(name, 'female') for name in names.words('female.txt')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjfK5ZKwDL__",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "fef1000d-e474-43f0-986d-10b721946e59"
      },
      "source": [
        "tagset[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Aamir', 'male'),\n",
              " ('Aaron', 'male'),\n",
              " ('Abbey', 'male'),\n",
              " ('Abbie', 'male'),\n",
              " ('Abbot', 'male'),\n",
              " ('Abbott', 'male'),\n",
              " ('Abby', 'male'),\n",
              " ('Abdel', 'male'),\n",
              " ('Abdul', 'male'),\n",
              " ('Abdulkarim', 'male')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZcAN-dmCrok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "b114852f-8e71-4121-fda3-21bb731353b4"
      },
      "source": [
        "random.shuffle(tagset)\n",
        "tagset[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Armond', 'male'),\n",
              " ('Leodora', 'female'),\n",
              " ('Webster', 'male'),\n",
              " ('Ashlen', 'female'),\n",
              " ('Talbert', 'male'),\n",
              " ('Reeva', 'female'),\n",
              " ('Linzy', 'female'),\n",
              " ('Veronique', 'female'),\n",
              " ('Fredrika', 'female'),\n",
              " ('Earle', 'male')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzK97C8BDmHR"
      },
      "source": [
        "fset = [(atributos(n), g) for (n, g) in tagset]\n",
        "train, test = fset[500:], fset[:500]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQPv0tW4Fd2G"
      },
      "source": [
        "**Modelo de clasificación Naive Bayes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37jueg4nDQFs"
      },
      "source": [
        "# entrenamiento del modelo NaiveBayes\n",
        "classifier = nltk.NaiveBayesClassifier.train(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BAWfUSHrEj3q"
      },
      "source": [
        " **Verificación de algunas predicciones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr8ytm8SEEZk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cf62ff8a-2722-4331-bf70-66aafff1d9e8"
      },
      "source": [
        "classifier.classify(atributos('amanda'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'female'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0GG1Y1_EPaO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6f286792-7845-44f8-b22b-1cf6815036a9"
      },
      "source": [
        "classifier.classify(atributos('peter'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'male'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSUK14XhEqLL"
      },
      "source": [
        "**Performance del modelo**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lenwC5agEdvT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "1ceb5e52-4db6-4c5f-c714-dbf72f90e652"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5S9qeCgsJSg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "6339e65d-d66e-4c96-9053-ea70d0abdea7"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7647770016120365\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSNI7OFxGib0"
      },
      "source": [
        "**Mejores atributos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5uaIAdDGlq8"
      },
      "source": [
        "def mas_atributos(nombre):\n",
        "    atrib = {}\n",
        "    atrib[\"primera_letra\"] = nombre[0].lower()\n",
        "    atrib[\"ultima_letra\"] = nombre[-1].lower()\n",
        "    for letra in 'abcdefghijklmnopqrstuvwxyz':\n",
        "        atrib[\"count({})\".format(letra)] = nombre.lower().count(letra)\n",
        "        atrib[\"has({})\".format(letra)] = (letra in nombre.lower())\n",
        "    return atrib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-gJIxKcHKvI"
      },
      "source": [
        "mas_atributos('jhon')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBu25HHgHQtK"
      },
      "source": [
        "fset = [(mas_atributos(n), g) for (n, g) in tagset]\n",
        "train, test = fset[500:], fset[:500]\n",
        "classifier2 = nltk.NaiveBayesClassifier.train(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hWR9hOzHlNe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "97d5f514-dfd5-474a-8755-4127a7bcb8dc"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier2, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.77\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rT7mmVnvFAcm"
      },
      "source": [
        "### Ejercicio de práctica\n",
        "\n",
        "**Objetivo:** Construye un classificador de nombres en español usando el siguiente dataset: \n",
        "https://github.com/jvalhondo/spanish-names-surnames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NphJqahkFnjO"
      },
      "source": [
        "1. **Preparación de los datos**: con un `git clone` puedes traer el dataset indicado a tu directorio en Colab, luego asegurate de darle el formato adecuado a los datos y sus features para que tenga la misma estructura del ejemplo anterior con el dataset `names` de nombres en ingles. \n",
        "\n",
        "* **Piensa y analiza**: ¿los features en ingles aplican de la misma manera para los nombres en español?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhbOT6_zFGHM"
      },
      "source": [
        "# escribe tu código aquí\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuY1Ux30F9uZ"
      },
      "source": [
        "2. **Entrenamiento y performance del modelo**: usando el classificador de Naive Bayes de NLTK entrena un modelo sencillo usando el mismo feature de la última letra del nombre, prueba algunas predicciones y calcula el performance del modelo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CvHwHTS8GT9I"
      },
      "source": [
        "# escribe tu código aquí\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4a2jv85GXA_"
      },
      "source": [
        "3. **Mejores atributos:** Define una función como `atributos2()` donde puedas extraer mejores atributos con los cuales entrenar una mejor version del clasificador. Haz un segundo entrenamiento y verifica como mejora el performance de tu modelo. ¿Se te ocurren mejores maneras de definir atributos para esta tarea particular?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9G-E5_CXIQiO"
      },
      "source": [
        "# escribe tu código aquí\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7CXFyfoGf4s"
      },
      "source": [
        "# Clasificación de documentos (email spam o no spam)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfli08sgIzl_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "7b634f01-0956-4843-8eb3-a4e5d2c77d3d"
      },
      "source": [
        "!git clone https://github.com/pachocamacho1990/datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'datasets' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHFKXxclJ5LC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "e2878b62-45ed-482a-faa2-92ce90b87731"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "from nltk import word_tokenize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33oKcvcjKrlM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "6183550d-66c9-41a4-e2a6-52c9da7ec461"
      },
      "source": [
        "df = pd.read_csv('datasets/email/csv/spam-apache.csv', names = ['clase','contenido'])\n",
        "df['tokens'] = df['contenido'].apply(lambda x: word_tokenize(x))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clase</th>\n",
              "      <th>contenido</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...</td>\n",
              "      <td>[&lt;, !, DOCTYPE, HTML, PUBLIC, ``, -//W3C//DTD,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>&gt; Russell Turpin:\\n&gt; &gt; That depends on how the...</td>\n",
              "      <td>[&gt;, Russell, Turpin, :, &gt;, &gt;, That, depends, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1</td>\n",
              "      <td>Help wanted.  We are a 14 year old fortune 500...</td>\n",
              "      <td>[Help, wanted, ., We, are, a, 14, year, old, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>Request A Free No Obligation Consultation!\\nAc...</td>\n",
              "      <td>[Request, A, Free, No, Obligation, Consultatio...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>Is there a way to look for a particular file o...</td>\n",
              "      <td>[Is, there, a, way, to, look, for, a, particul...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   clase  ...                                             tokens\n",
              "0     -1  ...  [<, !, DOCTYPE, HTML, PUBLIC, ``, -//W3C//DTD,...\n",
              "1      1  ...  [>, Russell, Turpin, :, >, >, That, depends, o...\n",
              "2     -1  ...  [Help, wanted, ., We, are, a, 14, year, old, f...\n",
              "3     -1  ...  [Request, A, Free, No, Obligation, Consultatio...\n",
              "4      1  ...  [Is, there, a, way, to, look, for, a, particul...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvHkYDylNMKP"
      },
      "source": [
        "df['tokens'].values[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4kw1BQUOe4-"
      },
      "source": [
        "all_words = nltk.FreqDist([w for tokenlist in df['tokens'].values for w in tokenlist])\n",
        "top_words = all_words.most_common(200)\n",
        "\n",
        "def document_features(document):\n",
        "    document_words = set(document)\n",
        "    features = {}\n",
        "    for word in top_words:\n",
        "        features['contains({})'.format(word)] = (word in document_words)\n",
        "    return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g6F_qNfmRAW"
      },
      "source": [
        "document_features(df['tokens'].values[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrCXXGMCn3zz"
      },
      "source": [
        "fset = [(document_features(texto), clase) for texto, clase in zip(df['tokens'].values, df['clase'].values)]\n",
        "random.shuffle(fset)\n",
        "train, test = fset[:200], fset[200:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6FGZE4OqkEa"
      },
      "source": [
        "classifier = nltk.NaiveBayesClassifier.train(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIyVc6lBrGOy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "01479a1e-6f68-4423-d4d3-6b1f9673f43c"
      },
      "source": [
        "print(nltk.classify.accuracy(classifier, test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.48\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x-R_PImrKIV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "outputId": "3b384c67-1640-422f-d9a1-19e41b42c667"
      },
      "source": [
        "classifier.show_most_informative_features(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Most Informative Features\n",
            "    contains(('us', 53)) = False               1 : -1     =      1.0 : 1.0\n",
            " contains(('could', 66)) = False               1 : -1     =      1.0 : 1.0\n",
            " contains(('money', 72)) = False               1 : -1     =      1.0 : 1.0\n",
            "  contains(('days', 40)) = False               1 : -1     =      1.0 : 1.0\n",
            "  contains(('need', 43)) = False               1 : -1     =      1.0 : 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wKzgha92up3l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        },
        "outputId": "ec079b59-5973-4084-e6ab-2f66037e92e5"
      },
      "source": [
        "df[df['clase']==-1]['contenido']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.0 Tr...\n",
              "2      Help wanted.  We are a 14 year old fortune 500...\n",
              "3      Request A Free No Obligation Consultation!\\nAc...\n",
              "10     >\\n>“µ×è¹µÑÇ ¡ÑºâÅ¡¸ØÃ¡Ô¨º¹ÍÔ¹àµÍÃìà¹çµ” \\n>àµ...\n",
              "11     ==============================================...\n",
              "                             ...                        \n",
              "243    ##############################################...\n",
              "244    Wanna see sexually curious teens playing with ...\n",
              "246    REQUEST FOR URGENT BUSINESS ASSISTANCE\\n------...\n",
              "248    Email marketing works!  There's no way around ...\n",
              "249    Email marketing works!  There's no way around ...\n",
              "Name: contenido, Length: 125, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeBvifrnr3GY"
      },
      "source": [
        "## Ejercicio de práctica\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR53vedlvd1O"
      },
      "source": [
        "¿Como podrías construir un mejor clasificador de documentos?\n",
        "\n",
        "0. **Dataset más grande:** El conjunto de datos que usamos fue muy pequeño, considera usar los archivos corpus que estan ubicados en la ruta: `datasets/email/plaintext/` \n",
        "\n",
        "1. **Limpieza:** como te diste cuenta no hicimos ningun tipo de limpieza de texto en los correos electrónicos. Considera usar expresiones regulares, filtros por categorias gramaticales, etc ... . \n",
        "\n",
        "---\n",
        "\n",
        "Con base en eso construye un dataset más grande y con un tokenizado más pulido. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw2KrtnymVT"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2ZO0aJyrTLx"
      },
      "source": [
        "# escribe tu código aquí:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V_KmDBHwiy8"
      },
      "source": [
        "2. **Validación del modelo anterior:**  \n",
        "---\n",
        "\n",
        "una vez tengas el nuevo conjunto de datos más pulido y de mayor tamaño, considera el mismo entrenamiento con el mismo tipo de atributos del ejemplo anterior, ¿mejora el accuracy del modelo resultante?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AM6Vhy-Fw8oj"
      },
      "source": [
        "# escribe tu código aquí:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lC72_CbxAoJ"
      },
      "source": [
        "3. **Construye mejores atributos**: A veces no solo se trata de las palabras más frecuentes sino de el contexto, y capturar contexto no es posible solo viendo los tokens de forma individual, ¿que tal si consideramos bi-gramas, tri-gramas ...?, ¿las secuencias de palabras podrián funcionar como mejores atributos para el modelo?. Para ver si es así,  podemos extraer n-gramas de nuestro corpus y obtener sus frecuencias de aparición con `FreqDist()`, desarrolla tu propia manera de hacerlo y entrena un modelo con esos nuevos atributos, no olvides compartir tus resultados en la sección de comentarios. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtMkQWpfxoy3"
      },
      "source": [
        "# escribe tu código aquí:\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}